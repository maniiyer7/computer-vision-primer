{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification \n",
    "\n",
    "In image classification, we try to assign a class label to an image based on the prominent objects contained inside the image.\n",
    "\n",
    "Example:\n",
    "* Classifying images from a zoo according to the species\n",
    "* Classifying images of hand-written digits to the correct digit\n",
    "\n",
    "## What we'll be doing\n",
    "\n",
    "Digits (MNIST) with Logistic Regression!\n",
    "\n",
    "* Read images\n",
    "* Visualise them\n",
    "* Flatten the images\n",
    "* Resample for machine learning\n",
    "* Build Models\n",
    "* Predict on new data\n",
    "* Model assessment\n",
    "\n",
    "## Get the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DESCR': 'Optical Recognition of Handwritten Digits Data Set\\n'\n",
      "          '===================================================\\n'\n",
      "          '\\n'\n",
      "          'Notes\\n'\n",
      "          '-----\\n'\n",
      "          'Data Set Characteristics:\\n'\n",
      "          '    :Number of Instances: 5620\\n'\n",
      "          '    :Number of Attributes: 64\\n'\n",
      "          '    :Attribute Information: 8x8 image of integer pixels in the '\n",
      "          'range 0..16.\\n'\n",
      "          '    :Missing Attribute Values: None\\n'\n",
      "          \"    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n\"\n",
      "          '    :Date: July; 1998\\n'\n",
      "          '\\n'\n",
      "          'This is a copy of the test set of the UCI ML hand-written digits '\n",
      "          'datasets\\n'\n",
      "          'http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n'\n",
      "          '\\n'\n",
      "          'The data set contains images of hand-written digits: 10 classes '\n",
      "          'where\\n'\n",
      "          'each class refers to a digit.\\n'\n",
      "          '\\n'\n",
      "          'Preprocessing programs made available by NIST were used to extract\\n'\n",
      "          'normalized bitmaps of handwritten digits from a preprinted form. '\n",
      "          'From a\\n'\n",
      "          'total of 43 people, 30 contributed to the training set and '\n",
      "          'different 13\\n'\n",
      "          'to the test set. 32x32 bitmaps are divided into nonoverlapping '\n",
      "          'blocks of\\n'\n",
      "          '4x4 and the number of on pixels are counted in each block. This '\n",
      "          'generates\\n'\n",
      "          'an input matrix of 8x8 where each element is an integer in the '\n",
      "          'range\\n'\n",
      "          '0..16. This reduces dimensionality and gives invariance to small\\n'\n",
      "          'distortions.\\n'\n",
      "          '\\n'\n",
      "          'For info on NIST preprocessing routines, see M. D. Garris, J. L. '\n",
      "          'Blue, G.\\n'\n",
      "          'T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, '\n",
      "          'and C.\\n'\n",
      "          'L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR '\n",
      "          '5469,\\n'\n",
      "          '1994.\\n'\n",
      "          '\\n'\n",
      "          'References\\n'\n",
      "          '----------\\n'\n",
      "          '  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and '\n",
      "          'Their\\n'\n",
      "          '    Applications to Handwritten Digit Recognition, MSc Thesis, '\n",
      "          'Institute of\\n'\n",
      "          '    Graduate Studies in Science and Engineering, Bogazici '\n",
      "          'University.\\n'\n",
      "          '  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, '\n",
      "          'Kybernetika.\\n'\n",
      "          '  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai '\n",
      "          'Qin.\\n'\n",
      "          '    Linear dimensionalityreduction using relevance weighted LDA. '\n",
      "          'School of\\n'\n",
      "          '    Electrical and Electronic Engineering Nanyang Technological '\n",
      "          'University.\\n'\n",
      "          '    2005.\\n'\n",
      "          '  - Claudio Gentile. A New Approximate Maximal Margin '\n",
      "          'Classification\\n'\n",
      "          '    Algorithm. NIPS. 2000.\\n',\n",
      " 'data': array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
      "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
      "       ..., \n",
      "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
      "       [  0.,   0.,  10., ...,  12.,   1.,   0.]]),\n",
      " 'images': array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
      "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
      "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
      "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
      "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
      "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
      "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
      "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
      "\n",
      "       ..., \n",
      "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
      "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
      "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
      "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
      "        ..., \n",
      "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
      "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
      "\n",
      "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
      "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
      "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
      "        ..., \n",
      "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
      "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
      "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]]),\n",
      " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
      " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "pprint(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Images\n",
    "\n",
    "* The data that we are interested in is made of 8x8 images of digits.\n",
    "* Let's have a look at the first 8 images, stored in the `images` attribute of the dataset.\n",
    "* For these images, we know which digit they represent: it is given in the 'target' of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIbgBoBk/hfcRwrybfY3MgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f767f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:8]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten the Images\n",
    "\n",
    "To apply a classifier on this data, we need to flatten the image, to turn the data in a (samples, feature) matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a classifier: a logistic regression classifier\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.97      0.96        88\n",
      "          1       0.86      0.89      0.88        91\n",
      "          2       0.98      0.98      0.98        86\n",
      "          3       0.99      0.82      0.90        91\n",
      "          4       0.99      0.93      0.96        92\n",
      "          5       0.83      0.90      0.86        91\n",
      "          6       0.94      0.99      0.96        91\n",
      "          7       0.98      0.89      0.93        89\n",
      "          8       0.89      0.88      0.88        88\n",
      "          9       0.83      0.92      0.87        92\n",
      "\n",
      "avg / total       0.92      0.92      0.92       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[85  0  0  0  1  1  1  0  0  0]\n",
      " [ 0 81  0  1  0  0  1  0  2  6]\n",
      " [ 2  0 84  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 75  0  6  0  2  5  2]\n",
      " [ 1  2  0  0 86  0  1  0  0  2]\n",
      " [ 0  3  0  0  0 82  2  0  0  4]\n",
      " [ 0  0  1  0  0  0 90  0  0  0]\n",
      " [ 0  1  0  0  0  5  0 79  1  3]\n",
      " [ 0  5  1  0  0  3  1  0 77  1]\n",
      " [ 2  1  0  0  0  2  0  0  2 85]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916573971079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\\n\" % (metrics.accuracy_score(expected, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115f76cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
